{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is created by this [sql query](https://console.cloud.google.com/bigquery?sq=123474043329:01abf8866144486f932c756730ddaff1) in BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and partition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://storage.googleapis.com/codenet/issue_labels/'\n",
    "df = pd.concat([pd.read_csv(base_url+f'00000000000{i}.csv.gz') for i in range(10)])\n",
    "df = df[df['num_concurrent_classes'] <= 1]\n",
    "df.to_pickle('labeled_issues_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on filtering based on **num_concurrent_classes** field:  \n",
    "\n",
    "0 concurrent classes mean cases where issues are not classified as `Bug`, `Feature` or `Question`.  1 concurrent classes are cases where only 1 of `Bug`, `Feature` or `Question` are classified.  Given the very small overlap betwen the three classes, we can filter out these examples in order to simplify our problem (turning multi-label classification into multi-class classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 4.6G Mar 26 16:52 labeled_issues_df.pkl\r\n"
     ]
    }
   ],
   "source": [
    "# see the size of the serialized dataframe\n",
    "!ls -lah labeled_issues_df.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4,984,719 rows 11 columns\n",
      "Test: 879,657 rows 11 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>repo</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>num_labels</th>\n",
       "      <th>labels</th>\n",
       "      <th>num_concurrent_classes</th>\n",
       "      <th>c_bug</th>\n",
       "      <th>c_feature</th>\n",
       "      <th>c_question</th>\n",
       "      <th>c_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68065</th>\n",
       "      <td>\"https://github.com/ESMCI/cime/issues/2435\"</td>\n",
       "      <td>ESMCI/cime</td>\n",
       "      <td>can we stop copying log files to the case dire...</td>\n",
       "      <td>i was talking to @cecilehannay about disk spac...</td>\n",
       "      <td>3</td>\n",
       "      <td>[\"in progress\", \"tp: CIMElib\", \"ty: enhancement\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75697</th>\n",
       "      <td>\"https://github.com/prescottprue/react-redux-f...</td>\n",
       "      <td>prescottprue/react-redux-firebase</td>\n",
       "      <td>isloaded helper always returns false when a de...</td>\n",
       "      <td>if you provide a default value to  datatojs  t...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"enhancement\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567001</th>\n",
       "      <td>\"https://github.com/denvaar/base64/issues/4\"</td>\n",
       "      <td>denvaar/base64</td>\n",
       "      <td>any improvement in general</td>\n",
       "      <td>any improvement/optimization to the code in ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>[\"hacktoberfest\"]</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url  \\\n",
       "68065         \"https://github.com/ESMCI/cime/issues/2435\"   \n",
       "75697   \"https://github.com/prescottprue/react-redux-f...   \n",
       "567001       \"https://github.com/denvaar/base64/issues/4\"   \n",
       "\n",
       "                                     repo  \\\n",
       "68065                          ESMCI/cime   \n",
       "75697   prescottprue/react-redux-firebase   \n",
       "567001                     denvaar/base64   \n",
       "\n",
       "                                                    title  \\\n",
       "68065   can we stop copying log files to the case dire...   \n",
       "75697   isloaded helper always returns false when a de...   \n",
       "567001                         any improvement in general   \n",
       "\n",
       "                                                     body  num_labels  \\\n",
       "68065   i was talking to @cecilehannay about disk spac...           3   \n",
       "75697   if you provide a default value to  datatojs  t...           1   \n",
       "567001  any improvement/optimization to the code in ge...           1   \n",
       "\n",
       "                                                   labels  \\\n",
       "68065   [\"in progress\", \"tp: CIMElib\", \"ty: enhancement\"]   \n",
       "75697                                     [\"enhancement\"]   \n",
       "567001                                  [\"hacktoberfest\"]   \n",
       "\n",
       "        num_concurrent_classes  c_bug  c_feature  c_question  c_other  \n",
       "68065                        1  False       True       False    False  \n",
       "75697                        1  False       True       False    False  \n",
       "567001                       0  False      False       False     True  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in data sample\n",
    "traindf, testdf = train_test_split(df, test_size=.15)\n",
    "\n",
    "\n",
    "#print out stats about shape of data\n",
    "print(f'Train: {traindf.shape[0]:,} rows {traindf.shape[1]:,} columns')\n",
    "print(f'Test: {testdf.shape[0]:,} rows {testdf.shape[1]:,} columns')\n",
    "\n",
    "# preview data\n",
    "traindf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.to_pickle('traindf.pkl')\n",
    "testdf.to_pickle('testdf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of The Dataset\n",
    "\n",
    "This data are issues and labels, with labels for certain categories grouped together.  The intention is to use this data to build a classifier that can auto-label issues.  There are three classes `Bug`, `Feature` or `Question` indicated by the `c_bug`, `c_feature`, and `c_question`, respectively in the pandas DataFrame illustrated above.  \n",
    "\n",
    "These labels were formed by grouping together human annotated labeled for issues, using the following hueristics (the below is SQL code):\n",
    "\n",
    "```{sql}\n",
    "  CASE when labels like '%bug%' and labels not like '%not bug%' then True else False end as c_bug,\n",
    "  \n",
    "  CASE when labels like '%feature%' or labels like '%enhancement%' or labels like '%improvement%' or labels like '%request%' then True else False end as c_feature,\n",
    "  \n",
    "  CASE when labels like '%question%' or labels like '%discussion%' then True else False end as c_question,\n",
    "```\n",
    "\n",
    "If the issue does not fall into one of these three categories the `c_other` flag is set to True.  This can be used as fourth class to classify.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Distribution of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c_bug         1212503\n",
       "c_feature     1231369\n",
       "c_question     255189\n",
       "c_other       2285658\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf[['c_bug', 'c_feature', 'c_question', 'c_other']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process Data For Deep Learning\n",
    "\n",
    "See this [repo](https://github.com/hamelsmu/ktext) for documentation on the ktext package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ktext.preprocess import processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i was talking to @cecilehannay about disk space issues on cheyenne. she pointed out that it's often useful to keep case directories around for a long time, but they take up much more space than they need to because the log files are copied into your case directory. can we stop copying log files into your case directory, just leaving them in your archive directory?\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_body_raw = traindf.body.tolist()\n",
    "train_title_raw = traindf.title.tolist()\n",
    "#preview output of first element\n",
    "train_body_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting maximum document length to 140 based upon hueristic of 0.8 percentile.\n",
      " See full histogram by insepecting the `document_length_stats` attribute.\n",
      "WARNING:root:(1/2) done. 1667 sec\n",
      "WARNING:root:....building corpus\n",
      "WARNING:root:(2/2) done. 337 sec\n",
      "WARNING:root:Finished parsing 4,984,719 documents.\n",
      "WARNING:root:...fit is finished, beginning transform\n",
      "WARNING:root:...padding data\n",
      "WARNING:root:done. 302 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 2s, sys: 2min 58s, total: 23min\n",
      "Wall time: 40min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Clean, tokenize, and apply padding / truncating such that each document length = 70\n",
    "#  also, retain only the top 8,000 words in the vocabulary and set the remaining words\n",
    "#  to 1 which will become common index for rare words \n",
    "body_pp = processor(hueristic_pct_padding=.8, keep_n=8000)\n",
    "train_body_vecs = body_pp.fit_transform(train_body_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:....tokenizing data\n",
      "WARNING:root:Setting maximum document length to 10 based upon hueristic of 0.8 percentile.\n",
      " See full histogram by insepecting the `document_length_stats` attribute.\n",
      "WARNING:root:(1/2) done. 238 sec\n",
      "WARNING:root:....building corpus\n",
      "WARNING:root:(2/2) done. 39 sec\n",
      "WARNING:root:Finished parsing 4,984,719 documents.\n",
      "WARNING:root:...fit is finished, beginning transform\n",
      "WARNING:root:...padding data\n",
      "WARNING:root:done. 64 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 22s, sys: 2min 14s, total: 5min 37s\n",
      "Wall time: 5min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Instantiate a text processor for the titles\n",
    "title_pp = processor(hueristic_pct_padding=.8, keep_n=5000)\n",
    "\n",
    "# process the title data\n",
    "train_title_vecs = title_pp.fit_transform(train_title_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look at one example of processed issue titles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "original string:\n",
      " can we stop copying log files to the case directory?\n",
      "after pre-processing:\n",
      " [  31  238  534 2330  162   60    2    5  347  305]\n"
     ]
    }
   ],
   "source": [
    "print('\\noriginal string:\\n', train_title_raw[0])\n",
    "print('after pre-processing:\\n', train_title_vecs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Transforms to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:...tokenizing data\n",
      "WARNING:root:...indexing data\n",
      "WARNING:root:...padding data\n",
      "WARNING:root:...tokenizing data\n",
      "WARNING:root:...indexing data\n",
      "WARNING:root:...padding data\n"
     ]
    }
   ],
   "source": [
    "test_body_raw = testdf.body.tolist()\n",
    "test_title_raw = testdf.title.tolist()\n",
    "\n",
    "test_body_vecs = body_pp.transform_parallel(test_body_raw)\n",
    "test_title_vecs = title_pp.transform_parallel(test_title_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serialize all of this to disk for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as dpickle\n",
    "import numpy as np\n",
    "\n",
    "# Save the preprocessor\n",
    "with open('body_pp.dpkl', 'wb') as f:\n",
    "    dpickle.dump(body_pp, f)\n",
    "\n",
    "with open('title_pp.dpkl', 'wb') as f:\n",
    "    dpickle.dump(title_pp, f)\n",
    "\n",
    "# Save the processed data\n",
    "np.save('train_title_vecs.npy', train_title_vecs)\n",
    "np.save('train_body_vecs.npy', train_body_vecs)\n",
    "np.save('test_body_vecs.npy', test_body_vecs)\n",
    "np.save('test_title_vecs.npy', test_title_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = traindf[['c_bug', 'c_feature', 'c_question', 'c_other']].astype(int).values.argmax(axis=1)\n",
    "test_labels = testdf[['c_bug', 'c_feature', 'c_question', 'c_other']].astype(int).values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_labels.npy', train_labels)\n",
    "np.save('test_labels.npy', test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_body_vecs.shape[0] == train_title_vecs.shape[0] == train_labels.shape[0]\n",
    "assert test_body_vecs.shape[0] == test_title_vecs.shape[0] == test_labels.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes about artifacts and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ds/MLapp/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 13G\r\n",
      "drwxr-xr-x 3 root root 6.0K Mar 26 22:36 .\r\n",
      "drwxr-xr-x 4 root root 6.0K Mar 26 05:47 ..\r\n",
      "drwxr-xr-x 2 root root 6.0K Mar 26 05:49 .ipynb_checkpoints\r\n",
      "-rw-r--r-- 1 root root  20K Mar 26 22:32 1_Download_and_Preprocess.ipynb\r\n",
      "-rw-r--r-- 1 root root  44K Mar 26 05:47 Demo.ipynb\r\n",
      "-rw-r--r-- 1 root root 249M Mar 26 22:01 body_pp.dpkl\r\n",
      "-rw-r--r-- 1 root root 4.6G Mar 26 16:52 labeled_issues_df.pkl\r\n",
      "-rw-r--r-- 1 root root 470M Mar 26 22:14 test_body_vecs.npy\r\n",
      "-rw-r--r-- 1 root root 6.8M Mar 26 22:36 test_labels.npy\r\n",
      "-rw-r--r-- 1 root root  34M Mar 26 22:14 test_title_vecs.npy\r\n",
      "-rw-r--r-- 1 root root 712M Mar 26 22:29 testdf.pkl\r\n",
      "-rw-r--r-- 1 root root  23M Mar 26 22:01 title_pp.dpkl\r\n",
      "-rw-r--r-- 1 root root 2.6G Mar 26 22:02 train_body_vecs.npy\r\n",
      "-rw-r--r-- 1 root root  39M Mar 26 22:36 train_labels.npy\r\n",
      "-rw-r--r-- 1 root root 191M Mar 26 22:01 train_title_vecs.npy\r\n",
      "-rw-r--r-- 1 root root 3.9G Mar 26 22:29 traindf.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
