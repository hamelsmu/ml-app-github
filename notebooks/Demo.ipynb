{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlapp import GitHubApp\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_id = 27079\n",
    "#key_file_path = '/Users/hamelsmu/.ssh/hamel-python-app.2019-03-15.private-key.pem'\n",
    "key_file_path = '/hamel-python-app.2019-03-15.private-key.pem'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the app installation\n",
    "\n",
    "The test installation automatically fetches the first installation the app is found on.  This app is only installed in one place, so this just fetches the installation made on the public `hamelsmu/example-github-app` repo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghapp = GitHubApp(pem_path=key_file_path, app_id=app_id)\n",
    "install = ghapp.get_test_installation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interact With Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue = install.create_issue(owner='hamelsmu',\n",
    "                             repository='example-github-app',\n",
    "                             title='test issue', \n",
    "                             body='this is automatically created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment on an issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IssueComment [ml-auto-labeler[bot]]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue.create_comment('Wooo!  Its time to do some machine learning!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a label to an issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ShortLabel [AI-is-taking-over]>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue.add_labels('AI-is-taking-over')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See the issue here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/hamelsmu/example-github-app/issues/13\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[https://github.com/hamelsmu/example-github-app/issues/13](https://github.com/hamelsmu/example-github-app/issues/13)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(issue.html_url)\n",
    "\n",
    "display.Markdown(f'[{issue.html_url}]({issue.html_url})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data For Training ML Models\n",
    "\n",
    "`Issue, Label` pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of issues which you can use to train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [02:20<00:00,  2.85it/s]\n"
     ]
    }
   ],
   "source": [
    "issues = GitHubApp.unpack_issues(client=install, \n",
    "                                 owner='kubeflow',\n",
    "                                 repo='kubeflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 372 issues with labels\n"
     ]
    }
   ],
   "source": [
    "print(f'there are {len(issues)} issues with labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kubeflow UIs does not display correctly on Firefox\n",
      "\n",
      "==Issue Body==\n",
      "All Kubeflow UIs are broken when browsing with Firefox. On the other hand, they display correctly when browsing with Chrome.\r\n",
      "\r\n",
      "This might be critical for 0.5, see screenshots below. I do not know if this a long-standing issue we haven't covered, let me know if you can reproduce it.\r\n",
      "\r\n",
      "@avdaredevil /cc @jlewi /cc @richardsliu \r\n",
      "\r\n",
      "Platform (GKE)\r\n",
      "=========\r\n",
      "**Kubernetes version**:\r\n",
      "```\r\n",
      "Server Version: version.Info{Major:\"1\", Minor:\"11+\", GitVersion:\"v1.11.7-gke.12\", GitCommit:\"06f08e60069231bd21bdf673cf0595aac80b99f6\", GitTr\r\n",
      "eeState:\"clean\", BuildDate:\"2019-02-25T20:37:10Z\", GoVersion:\"go1.10.8b4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\n",
      "```\r\n",
      "Kubeflow\r\n",
      "=======\r\n",
      "**Branch**: master\r\n",
      "**Commit**: https://github.com/kubeflow/kubeflow/commit/0969d745b817bbee7a9dbc3e2a1a7cd72c0dc469\r\n",
      "\r\n",
      "Client\r\n",
      "====\r\n",
      "**OS**: Ubuntu 18.04.1 LTS\r\n",
      "**Mozilla Firefox**: 66.0.1\r\n",
      "**Google Chrome** 73.0.3683.86\r\n",
      "\r\n",
      "Screenshots\r\n",
      "=========\r\n",
      "\r\n",
      "**[Chrome central dashboard]**\r\n",
      "![Chrome-central](https://user-images.githubusercontent.com/14974598/55174167-9c856980-5185-11e9-8056-1abf806398aa.png)\r\n",
      "\r\n",
      "**[Firefox central dashboard]**\r\n",
      "![Firefox-central](https://user-images.githubusercontent.com/14974598/55174192-a8712b80-5185-11e9-9fce-9491b0d782b2.png)\r\n",
      "\r\n",
      "**[Chrome docs]**\r\n",
      "![Chrome-docs](https://user-images.githubusercontent.com/14974598/55174209-af983980-5185-11e9-9baf-fe0f6b8da375.png)\r\n",
      "\r\n",
      "**[Firefox docs]**\r\n",
      "![Firefox-docs](https://user-images.githubusercontent.com/14974598/55174177-a27b4a80-5185-11e9-9891-0ca2cd2e46f8.png)\r\n",
      "\r\n",
      "**[Chrome tfjob dashboard]**\r\n",
      "![Chrome-tfjobs](https://user-images.githubusercontent.com/14974598/55174227-b757de00-5185-11e9-8029-f336d1229166.png)\r\n",
      "\r\n",
      "**[Firefox tfjob dashboard]**\r\n",
      "![Firefox-tfjobs](https://user-images.githubusercontent.com/14974598/55174240-bc1c9200-5185-11e9-8ad5-37671c6111cf.png)\r\n",
      "\r\n",
      "/kind bug\r\n",
      "/area front-end\n",
      "\n",
      "==Labels==\n",
      "['area/front-end', 'kind/bug', 'priority/p0']\n",
      "\n",
      "==Labels==\n",
      "https://github.com/kubeflow/kubeflow/issues/2847\n"
     ]
    }
   ],
   "source": [
    "print(issues[0].title)\n",
    "print('\\n==Issue Body==')\n",
    "print(issues[0].body)\n",
    "print('\\n==Labels==')\n",
    "print(issues[0].labels)\n",
    "print('\\n==Labels==')\n",
    "print(issues[0].url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from textacy.preprocess import preprocess_text\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def textacy_cleaner(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Defines the default function for cleaning text.\n",
    "    This function operates over a list.\n",
    "    \"\"\"\n",
    "    return preprocess_text(text,\n",
    "                           fix_unicode=True,\n",
    "                           lowercase=True,\n",
    "                           transliterate=True,\n",
    "                           no_urls=True,\n",
    "                           no_emails=True,\n",
    "                           no_phone_numbers=True,\n",
    "                           no_numbers=True,\n",
    "                           no_currency_symbols=True,\n",
    "                           no_punct=True,\n",
    "                           no_contractions=False,\n",
    "                           no_accents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Raw data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_titles = []\n",
    "raw_bodies = []\n",
    "\n",
    "for issue in issues:\n",
    "    raw_titles.append(textacy_cleaner(issue.title))\n",
    "    raw_bodies.append(textacy_cleaner(issue.body))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See top labels in Kubeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['priority/p2',\n",
       " 'priority/p1',\n",
       " 'area/jupyter',\n",
       " 'community/question',\n",
       " 'area/testing',\n",
       " 'platform/gcp',\n",
       " 'area/kfctl',\n",
       " 'area/inference',\n",
       " 'area/bootstrap',\n",
       " 'cla: yes',\n",
       " 'area/0.4.0',\n",
       " 'help wanted',\n",
       " 'cuj/multi-user',\n",
       " 'area/build-release',\n",
       " 'area/front-end',\n",
       " 'area/0.5.0',\n",
       " 'cuj/build-train-deploy',\n",
       " 'community/discussion']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "c = Counter()\n",
    "\n",
    "for label in labels:\n",
    "    c.update(label)\n",
    "    \n",
    "# only model on labels that occur at least 10 times\n",
    "labels_to_keep = [x[0] for x in c.most_common() if x[1]>=10]\n",
    "\n",
    "labels_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_keep = ['area/jupyter',\n",
    " 'area/kfctl',\n",
    " 'area/testing',\n",
    " 'area/inference',\n",
    " 'area/bootstrap',\n",
    " 'area/build-release',\n",
    " 'area/front-end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [[x for x in x if x in labels_to_keep] for x in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out records that do not contain one of the top labels in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = [bool(x) for x in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 200 issues out of the original 372 that have one of the top 10 labels\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {sum(mask)} issues out of the original {len(issues)} that have one of the top 10 labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_bodies = np.array(raw_bodies)[mask]\n",
    "filtered_titles = np.array(raw_titles)[mask]\n",
    "filtered_labels = np.array(labels)[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(filtered_bodies) == len(filtered_titles) == sum(mask) == len(filtered_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_train, text_val, labels_train, labels_val = train_test_split(filtered_text, filtered_labels, test_size=.15)\n",
    "\n",
    "b_t, b_v, t_t, t_v, l_t, l_v = train_test_split(filtered_bodies, \n",
    "                                                filtered_titles, \n",
    "                                                filtered_labels, \n",
    "                                                test_size=.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(b_t) == len(t_t) == len(l_t)\n",
    "assert len(b_v) == len(t_v) == len(l_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply TFIDF Transformation to titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=2)\n",
    "\n",
    "Xtitle_train = tfidf.fit_transform(t_t)\n",
    "Xtitle_test = tfidf.transform(t_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "ytrain = mlb.fit_transform(l_t)\n",
    "ytest = mlb.transform(l_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ytrain.shape[0] == Xtitle_train.shape[0]\n",
    "assert ytest.shape[0] == Xtitle_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we use transfer learning? Let's try using the weights from the Issue Summarizer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dill as dpickle\n",
    "from keras.models import load_model\n",
    "import seq2seq_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_Model = load_model('/ds/hamel/Seq2Seq_Tutorial/notebooks/seq2seq_model_tutorial.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = utils.extract_encoder_model(seq2seq_Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary for /ds/hamel/Seq2Seq_Tutorial/notebooks/body_pp.dpkl: 8,002\n"
     ]
    }
   ],
   "source": [
    "_, text_proc = utils.load_text_processor('/ds/hamel/Seq2Seq_Tutorial/notebooks/body_pp.dpkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xbody_train = encoder.predict(text_proc.transform(b_t.tolist()), batch_size=10)\n",
    "Xbody_test = encoder.predict(text_proc.transform(b_v.tolist()), batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import Model, optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "body-inp (InputLayer)           (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "title-inp (InputLayer)          (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 500)          0           body-inp[0][0]                   \n",
      "                                                                 title-inp[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 7)            3507        concat[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,507\n",
      "Trainable params: 3,507\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "body_inp = Input(shape=(Xbody_train.shape[1],), name='body-inp')\n",
    "title_inp = Input(shape=(Xtitle_train.shape[1],), name='title-inp')\n",
    "\n",
    "concat = Concatenate(name='concat')([body_inp, title_inp])\n",
    "h1 = Dense(50)(concat)\n",
    "out = Dense(ytrain.shape[1], activation='sigmoid')(concat)\n",
    "\n",
    "model = Model([body_inp, title_inp], out)\n",
    "adam = optimizers.Adam(lr = .01)\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170 samples, validate on 30 samples\n",
      "Epoch 1/20\n",
      "170/170 [==============================] - 3s 15ms/step - loss: 1.9667 - acc: 0.3118 - val_loss: 2.1445 - val_acc: 0.2667\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 0s 1ms/step - loss: 1.6412 - acc: 0.4765 - val_loss: 2.0595 - val_acc: 0.2667\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 0s 1ms/step - loss: 1.2260 - acc: 0.6882 - val_loss: 1.8103 - val_acc: 0.3000\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 0s 1ms/step - loss: 0.8815 - acc: 0.8176 - val_loss: 1.7915 - val_acc: 0.4000\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 0s 111us/step - loss: 0.6309 - acc: 0.8941 - val_loss: 1.8841 - val_acc: 0.4333\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 0s 107us/step - loss: 0.4839 - acc: 0.9294 - val_loss: 1.8888 - val_acc: 0.3333\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 0s 104us/step - loss: 0.3779 - acc: 0.9647 - val_loss: 1.9318 - val_acc: 0.4000\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 0s 109us/step - loss: 0.3251 - acc: 0.9412 - val_loss: 1.9439 - val_acc: 0.4000\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 0s 106us/step - loss: 0.2840 - acc: 0.9529 - val_loss: 1.9978 - val_acc: 0.4000\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 0s 109us/step - loss: 0.2537 - acc: 0.9882 - val_loss: 2.0305 - val_acc: 0.4000\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 0s 109us/step - loss: 0.2334 - acc: 0.9588 - val_loss: 2.0201 - val_acc: 0.3667\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 0s 113us/step - loss: 0.2176 - acc: 0.9765 - val_loss: 2.0707 - val_acc: 0.4000\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 0s 110us/step - loss: 0.2030 - acc: 0.9471 - val_loss: 2.1395 - val_acc: 0.4000\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 0s 104us/step - loss: 0.1935 - acc: 0.9588 - val_loss: 2.1463 - val_acc: 0.4000\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 0s 107us/step - loss: 0.1838 - acc: 0.9706 - val_loss: 2.1429 - val_acc: 0.4000\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 0s 108us/step - loss: 0.1773 - acc: 0.9647 - val_loss: 2.1702 - val_acc: 0.4000\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 0s 109us/step - loss: 0.1709 - acc: 0.9706 - val_loss: 2.2037 - val_acc: 0.4000\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 0s 109us/step - loss: 0.1657 - acc: 0.9647 - val_loss: 2.2305 - val_acc: 0.4000\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 0s 111us/step - loss: 0.1613 - acc: 0.9647 - val_loss: 2.2541 - val_acc: 0.4000\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 0s 111us/step - loss: 0.1576 - acc: 0.9588 - val_loss: 2.2594 - val_acc: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1097831e48>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc = ModelCheckpoint(filepath='transfer_learning_best_model.hdf5', save_best_only=True)\n",
    "\n",
    "model.fit(x=[Xbody_train, Xtitle_train],\n",
    "          y=ytrain, \n",
    "          validation_data=([Xbody_test, Xtitle_test], ytest), \n",
    "          epochs=20, \n",
    "          callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict([Xbody_test, Xtitle_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.argmax(ytest, axis=1) == np.argmax(test_predictions, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12 / 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = .1\n",
    "ground_truths = []\n",
    "predictions = []\n",
    "\n",
    "for i, data in enumerate(zip(mlb.inverse_transform(test_predictions >= threshold), mlb.inverse_transform(ytest))):\n",
    "    pred, ground_truth = data\n",
    "    ground_truths.append([ground_truth])\n",
    "    predictions.append([pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(area/kfctl,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(area/front-end,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(area/build-release,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(area/jupyter,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(area/jupyter, area/testing)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[(area/build-release,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[(area/front-end,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[(area/jupyter,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[(area/jupyter,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[(area/inference,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[(area/bootstrap,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[(area/inference,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[(area/inference,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[(area/testing,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[(area/front-end,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[(area/bootstrap,)]</td>\n",
       "      <td>[(area/bootstrap, area/kfctl, area/testing)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[(area/inference,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[(area/kfctl,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[(area/kfctl,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[(area/testing,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[(area/inference,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[(area/inference,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[(area/bootstrap,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[(area/testing,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[(area/bootstrap, area/testing)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[(area/kfctl,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[(area/testing,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[(area/bootstrap, area/testing)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[(area/jupyter,)]</td>\n",
       "      <td>[(area/jupyter,)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[(area/bootstrap,)]</td>\n",
       "      <td>[()]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ground_truth  \\\n",
       "0                    [(area/kfctl,)]   \n",
       "1                [(area/front-end,)]   \n",
       "2            [(area/build-release,)]   \n",
       "3                  [(area/jupyter,)]   \n",
       "4     [(area/jupyter, area/testing)]   \n",
       "5            [(area/build-release,)]   \n",
       "6                [(area/front-end,)]   \n",
       "7                  [(area/jupyter,)]   \n",
       "8                  [(area/jupyter,)]   \n",
       "9                [(area/inference,)]   \n",
       "10               [(area/bootstrap,)]   \n",
       "11               [(area/inference,)]   \n",
       "12               [(area/inference,)]   \n",
       "13                 [(area/testing,)]   \n",
       "14               [(area/front-end,)]   \n",
       "15               [(area/bootstrap,)]   \n",
       "16               [(area/inference,)]   \n",
       "17                   [(area/kfctl,)]   \n",
       "18                   [(area/kfctl,)]   \n",
       "19                 [(area/testing,)]   \n",
       "20               [(area/inference,)]   \n",
       "21               [(area/inference,)]   \n",
       "22               [(area/bootstrap,)]   \n",
       "23                 [(area/testing,)]   \n",
       "24  [(area/bootstrap, area/testing)]   \n",
       "25                   [(area/kfctl,)]   \n",
       "26                 [(area/testing,)]   \n",
       "27  [(area/bootstrap, area/testing)]   \n",
       "28                 [(area/jupyter,)]   \n",
       "29               [(area/bootstrap,)]   \n",
       "\n",
       "                                      prediction  \n",
       "0                                           [()]  \n",
       "1                                           [()]  \n",
       "2                                           [()]  \n",
       "3                                           [()]  \n",
       "4                                           [()]  \n",
       "5                                           [()]  \n",
       "6                                           [()]  \n",
       "7                                           [()]  \n",
       "8                                           [()]  \n",
       "9                                           [()]  \n",
       "10                                          [()]  \n",
       "11                                          [()]  \n",
       "12                                          [()]  \n",
       "13                                          [()]  \n",
       "14                                          [()]  \n",
       "15  [(area/bootstrap, area/kfctl, area/testing)]  \n",
       "16                                          [()]  \n",
       "17                                          [()]  \n",
       "18                                          [()]  \n",
       "19                                          [()]  \n",
       "20                                          [()]  \n",
       "21                                          [()]  \n",
       "22                                          [()]  \n",
       "23                                          [()]  \n",
       "24                                          [()]  \n",
       "25                                          [()]  \n",
       "26                                          [()]  \n",
       "27                                          [()]  \n",
       "28                             [(area/jupyter,)]  \n",
       "29                                          [()]  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'ground_truth':ground_truths, 'prediction': predictions})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:  \n",
    "\n",
    "This simple model sucks, need to find something more compelling in this situation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
