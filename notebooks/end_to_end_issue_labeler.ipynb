{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "End to end issue labeler",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qTmLBxDxBAZL"
      },
      "source": [
        "# Run in colab and please Choose a GPU/TPU runtime in colab before preceed \n",
        "----\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/machine-learning-apps/Issue-Label-Bot/blob/master/notebooks/end_to_end_issue_labeler.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPuJWziKT0jE",
        "colab_type": "code",
        "outputId": "d23e2c62-b845-4cd9-e82b-54cbb023a36e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "!pip install -q tensorflow-hub\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, GRU, Dense, Embedding, BatchNormalization, Concatenate\n",
        "from tensorflow.keras import  Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.cloud import bigquery\n",
        "\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Version:  2.0.0\n",
            "Eager mode:  True\n",
            "Hub version:  0.7.0\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwM9LWgXewJ0",
        "colab_type": "text"
      },
      "source": [
        "### Provide your credentials to the runtime for bigquery purpose"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkGOn0e9etmg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11145354-f61c-4afc-f8dd-d1f8615e2100"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authenticated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26u34SrteaW3",
        "colab_type": "text"
      },
      "source": [
        "# Define some hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SiAEMkgcCKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_count = 200000\n",
        "labels = ['unknown',   'bug',  'feature',   'question']\n",
        "num_classes=len(labels)\n",
        "test_size=0.33\n",
        "random_state=42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cLh05lDpJ4wj",
        "colab": {}
      },
      "source": [
        "client = bigquery.Client(project='shopify-codelab-and-demos')\n",
        "\n",
        "\n",
        "df = client.query(r\"\"\"\n",
        " with data as (\n",
        "   SELECT\n",
        "       LOWER(TRIM(REGEXP_REPLACE(JSON_EXTRACT(payload, '$.issue.title'), r\"\\\\n|\\\\r|\\(|\\)|\\[|\\]|#|\\*|`|\\\"\", ' '))) as title\n",
        "      , LOWER(TRIM(REGEXP_REPLACE(JSON_EXTRACT(payload, '$.issue.body'), r\"\\\\n|\\\\r|\\(|\\)|\\[|\\]|#|\\*|`|\\\"\", ' '))) as body\n",
        "      , REGEXP_EXTRACT_ALL(LOWER(TRIM(JSON_EXTRACT(payload, \"$.issue.labels\"))), ',\"name\\\":\"(.+?)\",\"color') as labels\n",
        "    FROM `githubarchive.year.20*`\n",
        "    WHERE\n",
        "    _TABLE_SUFFIX BETWEEN '16' and '18'\n",
        "    and type=\"IssuesEvent\"\n",
        "    )\n",
        "    select title, body, CASE when label like '%bug%' and label not like '%not bug%' then 1\n",
        "                             when label like '%feature%' or label like '%enhancement%' or label like '%improvement%' or label like '%request%' then 2\n",
        "                             when label like '%question%' or label like '%discussion%' then 3\n",
        "                             else 0 end as y,\n",
        "                         CASE when label like '%bug%' and label not like '%not bug%' then 'bug'\n",
        "                             when label like '%feature%' or label like '%enhancement%' or label like '%improvement%' or label like '%request%' then 'feature'\n",
        "                             when label like '%question%' or label like '%discussion%' then 'question'\n",
        "                             else 'unknown' end as y_name\n",
        "    from data, unnest(labels) label\n",
        "    where\n",
        "    ARRAY_LENGTH(SPLIT(body, ' ')) >= 6\n",
        "    and ARRAY_LENGTH(SPLIT(title, ' ')) >= 3\n",
        "    and ARRAY_LENGTH(SPLIT(title, ' ')) <= 50\n",
        "    and ARRAY_LENGTH(SPLIT(body, ' ')) <= 1000\n",
        "limit {sample_count}\n",
        "  \"\"\".format(sample_count=sample_count)).to_dataframe() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xgopBClCKs_0",
        "colab": {}
      },
      "source": [
        "X = df[['title', 'body']]\n",
        "y = df['y']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weU7s0OhYaQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=test_size, random_state=random_state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHfZ_1B5Sqt_",
        "colab_type": "code",
        "outputId": "72903519-95db-485c-f6ac-d082bc8316d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "\n",
        "\n",
        "# define pre-trained embedding\n",
        "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
        "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
        "                           dtype=tf.string, trainable=True)\n",
        "\n",
        "# define two sets of inputs\n",
        "text = Input(shape=(2), dtype=tf.string, name=\"title_and_body\")\n",
        " \n",
        "title = hub_layer(text[:,0])[:, :, tf.newaxis]\n",
        "body = hub_layer(text[:,1])[:, :, tf.newaxis]\n",
        "\n",
        "data = Concatenate(axis=2, name='Concat')([body, title])\n",
        "\n",
        "\n",
        "data = BatchNormalization()(data)\n",
        "data = GRU(75, name='Title-Encoder')(data)\n",
        "\n",
        "x = BatchNormalization()(data)\n",
        "out = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# our model will accept the inputs of the two branches and\n",
        "# then output a single value\n",
        "model = Model(inputs=text , outputs=out)\n",
        "model.summary()\n",
        "\n",
        "\n",
        " \n",
        "\n",
        " "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "title_and_body (InputLayer)     [(None, 2)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_2 (Te [(None,)]            0           title_and_body[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None,)]            0           title_and_body[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        (None, 20)           400020      tf_op_layer_strided_slice[0][0]  \n",
            "                                                                 tf_op_layer_strided_slice_2[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_3 (Te [(None, 20, 1)]      0           keras_layer[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_1 (Te [(None, 20, 1)]      0           keras_layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Concat (Concatenate)            (None, 20, 2)        0           tf_op_layer_strided_slice_3[0][0]\n",
            "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 20, 2)        8           Concat[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "Title-Encoder (GRU)             (None, 75)           17775       batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 75)           300         Title-Encoder[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 4)            304         batch_normalization_1[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 418,407\n",
            "Trainable params: 418,253\n",
            "Non-trainable params: 154\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c2YkczcTT4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=Adam(lr=0.001), \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fmT1ThiS6pa",
        "colab_type": "code",
        "outputId": "9fbcfa61-14bb-42ea-993c-dc2ecd230c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "batch_size = 900\n",
        "epochs = 4\n",
        "history = model.fit(x=X_train.values, \n",
        "                    y=y_train.values,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=[X_test.values, y_test.values]\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 134000 samples, validate on 66000 samples\n",
            "Epoch 1/4\n",
            "134000/134000 [==============================] - 23s 172us/sample - loss: 1.1302 - accuracy: 0.5559 - val_loss: 1.0360 - val_accuracy: 0.6037\n",
            "Epoch 2/4\n",
            "134000/134000 [==============================] - 20s 147us/sample - loss: 0.9493 - accuracy: 0.6018 - val_loss: 1.0206 - val_accuracy: 0.6037\n",
            "Epoch 3/4\n",
            "134000/134000 [==============================] - 20s 148us/sample - loss: 0.9182 - accuracy: 0.6052 - val_loss: 0.9551 - val_accuracy: 0.6037\n",
            "Epoch 4/4\n",
            "134000/134000 [==============================] - 18s 136us/sample - loss: 0.9018 - accuracy: 0.6087 - val_loss: 0.9145 - val_accuracy: 0.6056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLnYGwfodEpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "single_predict = lambda data: dict(zip(labels, model.predict([data])[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FAdp9_IdS6r",
        "colab_type": "code",
        "outputId": "7e75467b-7463-448d-ad30-4b6574acfe5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "single_predict(['allow layers to be added to the spiderfier aft...\t', 'currently the spiderfier works with multiple l...\t'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bug': 0.04751177,\n",
              " 'feature': 0.3074346,\n",
              " 'question': 0.023045829,\n",
              " 'unknown': 0.62200785}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DnW5B6yS6st",
        "colab_type": "code",
        "outputId": "88d8773d-9bf8-480c-f083-74d43f443379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "single_predict(['requesting a button', 'It would be great to add a new button'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bug': 0.016338741,\n",
              " 'feature': 0.40941617,\n",
              " 'question': 0.014603957,\n",
              " 'unknown': 0.5596412}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ2CVXUpS6u_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('gs://pengyu-ml-test/issue_labler_e2d/weights')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEfe8nsniGQD",
        "colab_type": "text"
      },
      "source": [
        "# Bug in keras with tf-hub during save to saved_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkc6gqPWS60m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "37c7d6ae-6349-4cef-fe0b-e5089ee3512b"
      },
      "source": [
        "model.save('local')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-57bc6d187101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'local'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    973\u001b[0m     \"\"\"\n\u001b[1;32m    974\u001b[0m     saving.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m--> 975\u001b[0;31m                       signatures, options)\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 115\u001b[0;31m                           signatures, options)\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0;31m# default learning phase placeholder.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0msave_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m    881\u001b[0m   \u001b[0;31m# Note we run this twice since, while constructing the view the first time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   \u001b[0;31m# there can be side effects of creating variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SaveableView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_graph_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m   \u001b[0msaveable_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SaveableView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_graph_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/saved_model/save.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, checkpoint_view)\u001b[0m\n\u001b[1;32m    188\u001b[0m           \u001b[0mconcrete_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconcrete_function\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcrete_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m           \u001b[0;32mif\u001b[0m \u001b[0mconcrete_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen_function_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0mseen_function_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcrete_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'name'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTE2o0O5aUXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
